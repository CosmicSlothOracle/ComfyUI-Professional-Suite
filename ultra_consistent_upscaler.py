#!/usr/bin/env python3
"""
ULTRA-CONSISTENT PIXEL ART UPSCALER
10 Workflow-Verbesserungen gegen weiÃŸe Fraktale und Inkonsistenzen
"""
import os
import sys
from pathlib import Path
import imageio
import cv2
import numpy as np
from tqdm import tqdm
# Removed sklearn dependency


class UltraConsistentUpscaler:
    def __init__(self):
        self.base_dir = Path(__file__).parent.absolute()
        self.input_dir = self.base_dir / "input"
        self.output_dir = self.base_dir / "output"
        self.output_dir.mkdir(exist_ok=True)

        # Globale Konsistenz-Parameter
        self.global_palette = None
        self.frame_history = []
        self.consistency_threshold = 0.3

    # WORKFLOW 1: GLOBALE FARBPALETTEN-KONSISTENZ
    def extract_global_palette(self, frames, n_colors=16):
        """Extrahiert eine globale Farbpalette fÃ¼r die gesamte Animation"""
        print("ğŸ¨ Workflow 1: Globale Farbpaletten-Extraktion")

        all_pixels = []
        sample_rate = max(1, len(frames) // 10)

        for i in range(0, len(frames), sample_rate):
            frame = frames[i]
            if frame.shape[-1] == 4:
                frame = frame[:, :, :3]

            small_frame = cv2.resize(frame, (32, 32))
            pixels = small_frame.reshape(-1, 3)
            all_pixels.extend(pixels[::4])  # Subsample

        all_pixels = np.array(all_pixels)
        if len(all_pixels) > n_colors:
            # Einfache Farbquantisierung
            unique_colors = np.unique(all_pixels.reshape(-1, 3), axis=0)
            if len(unique_colors) > n_colors:
                # RegelmÃ¤ÃŸige Sampling der Farben
                indices = np.linspace(
                    0, len(unique_colors)-1, n_colors, dtype=int)
                self.global_palette = unique_colors[indices]
            else:
                self.global_palette = unique_colors

        return self.global_palette

    # WORKFLOW 2: ADAPTIVE SCHÃ„RFUNG MIT RAUSCH-UNTERDRÃœCKUNG
    def adaptive_sharpen_safe(self, image, strength=0.3):
        """Adaptive SchÃ¤rfung die weiÃŸe Fraktale verhindert"""
        print("âš¡ Workflow 2: Anti-Fraktal SchÃ¤rfung")

        # RauschunterdrÃ¼ckung
        denoised = cv2.bilateralFilter(image, 5, 50, 50)

        # Sanfte SchÃ¤rfung
        kernel = np.array([[-0.5, -0.5, -0.5], [-0.5, 5, -0.5],
                          [-0.5, -0.5, -0.5]], dtype=np.float32)
        sharpened = cv2.filter2D(denoised, -1, kernel * strength)

        # Mit Original mischen
        result = cv2.addWeighted(denoised, 0.7, sharpened, 0.3, 0)

        return np.clip(result, 0, 255).astype(np.uint8)

    # WORKFLOW 3: TEMPORAL KONSISTENZ MIT FRAME-PUFFER
    def temporal_consistency_filter(self, current_frame, buffer_size=3):
        """Temporal filtering fÃ¼r Frame-zu-Frame Konsistenz"""
        print("ğŸ¬ Workflow 3: Temporal Konsistenz")

        self.frame_history.append(current_frame.copy())

        if len(self.frame_history) > buffer_size:
            self.frame_history.pop(0)

        if len(self.frame_history) < 2:
            return current_frame

        # Gewichteter Durchschnitt
        result = current_frame.astype(np.float32) * 0.7
        for i, frame in enumerate(self.frame_history[:-1]):
            weight = 0.3 / len(self.frame_history[:-1])
            result += frame.astype(np.float32) * weight

        return np.clip(result, 0, 255).astype(np.uint8)

    # WORKFLOW 4: INTELLIGENTE PIXELART-STILISIERUNG
    def intelligent_pixelart(self, frame, pixel_factor=3):
        """Pixelart-Effekt der Originalstrukturen respektiert"""
        print("ğŸ¯ Workflow 4: Intelligente Pixelart-Stilisierung")

        h, w = frame.shape[:2]

        # Struktur-erhaltende Verkleinerung
        small = cv2.resize(frame, (w//pixel_factor, h//pixel_factor),
                           interpolation=cv2.INTER_AREA)

        # Farbquantisierung mit globaler Palette
        if self.global_palette is not None and len(self.global_palette) > 0:
            small_flat = small.reshape(-1, 3).astype(np.float32)
            palette_flat = self.global_palette.astype(np.float32)

            # NÃ¤chste Farbe finden
            for i, pixel in enumerate(small_flat):
                distances = np.sum((palette_flat - pixel) ** 2, axis=1)
                closest_idx = np.argmin(distances)
                small_flat[i] = palette_flat[closest_idx]

            small = small_flat.reshape(small.shape).astype(np.uint8)

        # ZurÃ¼ck zur OriginalgrÃ¶ÃŸe
        pixelized = cv2.resize(small, (w, h), interpolation=cv2.INTER_NEAREST)

        return pixelized

    # WORKFLOW 5: GRADIENT-BASIERTE KANTENVERSTÃ„RKUNG
    def gradient_edge_enhancement(self, image, strength=0.2):
        """Sanfte KantenverstÃ¤rkung ohne Fraktal-Artefakte"""
        print("ğŸ“ Workflow 5: Gradient-KantenverstÃ¤rkung")

        # Gradientenberechnung
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
        grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)

        # GradientenstÃ¤rke
        gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)
        gradient_magnitude = np.clip(gradient_magnitude / 255.0, 0, 1)

        # Sanfte VerstÃ¤rkung nur bei moderaten Gradienten
        mask = (gradient_magnitude > 0.1) & (gradient_magnitude < 0.7)

        enhanced = image.copy().astype(np.float32)
        for c in range(3):
            enhanced[:, :, c] = np.where(mask,
                                         enhanced[:, :, c] *
                                         (1 + strength * gradient_magnitude),
                                         enhanced[:, :, c])

        return np.clip(enhanced, 0, 255).astype(np.uint8)

    # WORKFLOW 6: MULTI-SCALE UPSCALING
    def multi_scale_upscale(self, frame, target_scale=2.5):
        """Mehrstufiges Upscaling fÃ¼r natÃ¼rliche VergrÃ¶ÃŸerung"""
        print("ğŸ” Workflow 6: Multi-Scale Upscaling")

        h, w = frame.shape[:2]

        # Stufenweise VergrÃ¶ÃŸerung
        intermediate = cv2.resize(frame, (int(w * 1.5), int(h * 1.5)),
                                  interpolation=cv2.INTER_CUBIC)

        final = cv2.resize(intermediate, (int(w * target_scale), int(h * target_scale)),
                           interpolation=cv2.INTER_LANCZOS4)

        return final

    # WORKFLOW 7: HISTOGRAM-MATCHING FÃœR KONSISTENZ
    def histogram_matching(self, source, reference):
        """Histogram Matching fÃ¼r konsistente Beleuchtung"""
        print("ğŸ“Š Workflow 7: Histogram Matching")

        matched = np.zeros_like(source)

        for c in range(3):
            source_hist, bins = np.histogram(
                source[:, :, c].flatten(), 256, [0, 256])
            ref_hist, _ = np.histogram(
                reference[:, :, c].flatten(), 256, [0, 256])

            # CDF berechnen
            source_cdf = source_hist.cumsum()
            ref_cdf = ref_hist.cumsum()

            # Normalisieren
            source_cdf = source_cdf / source_cdf[-1]
            ref_cdf = ref_cdf / ref_cdf[-1]

            # Mapping erstellen
            mapping = np.interp(source_cdf, ref_cdf, np.arange(256))
            matched[:, :, c] = mapping[source[:, :, c]]

        return matched.astype(np.uint8)

    # WORKFLOW 8: STRUKTUR-ERHALTENDE GLÃ„TTUNG
    def structure_preserving_smooth(self, image, iterations=2):
        """GlÃ¤ttung die wichtige Strukturen erhÃ¤lt"""
        print("ğŸŒŠ Workflow 8: Struktur-erhaltende GlÃ¤ttung")

        result = image.copy()

        for _ in range(iterations):
            # Edge-preserving filter
            result = cv2.edgePreservingFilter(
                result, flags=2, sigma_s=50, sigma_r=0.4)

        return result

    # WORKFLOW 9: LOKALE KONTRAST-NORMALISIERUNG
    def local_contrast_normalization(self, image, window_size=15):
        """Lokale Kontrast-Normalisierung gegen Ãœber-/Unterbelichtung"""
        print("ğŸ”† Workflow 9: Lokale Kontrast-Normalisierung")

        # Zu Grayscale fÃ¼r Berechnung
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        # Lokaler Mittelwert und Standardabweichung
        kernel = np.ones((window_size, window_size),
                         np.float32) / (window_size**2)
        local_mean = cv2.filter2D(gray.astype(np.float32), -1, kernel)
        local_sqr_mean = cv2.filter2D((gray.astype(np.float32))**2, -1, kernel)
        local_std = np.sqrt(np.maximum(local_sqr_mean - local_mean**2, 0))

        # Normalisierung
        normalized_gray = (gray.astype(np.float32) -
                           local_mean) / (local_std + 1e-6)
        normalized_gray = np.clip(normalized_gray * 50 + 128, 0, 255)

        # ZurÃ¼ck zu Farbe mit erhaltenen Proportionen
        result = image.copy().astype(np.float32)
        for c in range(3):
            result[:, :, c] = result[:, :, c] * \
                (normalized_gray / (gray + 1e-6))

        return np.clip(result, 0, 255).astype(np.uint8)

    # WORKFLOW 10: FRAME-INTERPOLATION FÃœR FLÃœSSIGKEIT
    def frame_interpolation_smooth(self, frames):
        """Frame-Interpolation fÃ¼r flÃ¼ssigere Animationen"""
        print("ğŸ­ Workflow 10: Frame-Interpolation")

        if len(frames) < 2:
            return frames

        smoothed_frames = [frames[0]]

        for i in range(1, len(frames)):
            prev_frame = frames[i-1].astype(np.float32)
            curr_frame = frames[i].astype(np.float32)

            # Optischer Fluss fÃ¼r BewegungsschÃ¤tzung
            prev_gray = cv2.cvtColor(frames[i-1], cv2.COLOR_BGR2GRAY)
            curr_gray = cv2.cvtColor(frames[i], cv2.COLOR_BGR2GRAY)

            flow = cv2.calcOpticalFlowPyrLK(prev_gray, curr_gray, None, None)

            # Sanfte Interpolation basierend auf Bewegung
            alpha = 0.7  # Gewichtung aktuelles Frame
            interpolated = alpha * curr_frame + (1 - alpha) * prev_frame

            smoothed_frames.append(
                np.clip(interpolated, 0, 255).astype(np.uint8))

        return smoothed_frames

    def process_gif_ultra_consistent(self, gif_path):
        """Haupt-Verarbeitungsschleife mit allen 10 Workflows"""
        print(f"\nğŸš€ ULTRA-CONSISTENT PROCESSING: {gif_path.name}")
        print("=" * 80)

        try:
            # GIF laden
            frames = imageio.mimread(gif_path)
            print(f"ğŸ“¹ {len(frames)} Frames geladen")

            # WORKFLOW 1: Globale Palette extrahieren
            self.extract_global_palette(frames, n_colors=16)
            self.frame_history = []  # Reset

            processed_frames = []
            reference_frame = None

            for i, frame in enumerate(tqdm(frames, desc="Ultra-Processing")):
                # RGBA -> RGB
                if frame.shape[-1] == 4:
                    frame = frame[:, :, :3]

                bgr_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)

                # WORKFLOW 4: Intelligente Pixelart-Stilisierung
                pixelized = self.intelligent_pixelart(
                    bgr_frame, pixel_factor=3)

                # WORKFLOW 6: Multi-Scale Upscaling
                upscaled = self.multi_scale_upscale(
                    pixelized, target_scale=2.2)

                # WORKFLOW 8: Struktur-erhaltende GlÃ¤ttung
                smoothed = self.structure_preserving_smooth(upscaled)

                # WORKFLOW 2: Anti-Fraktal SchÃ¤rfung
                sharpened = self.adaptive_sharpen_safe(smoothed, strength=0.2)

                # WORKFLOW 5: Gradient-KantenverstÃ¤rkung
                enhanced = self.gradient_edge_enhancement(
                    sharpened, strength=0.15)

                # WORKFLOW 9: Lokale Kontrast-Normalisierung
                normalized = self.local_contrast_normalization(enhanced)

                # WORKFLOW 7: Histogram Matching (ab 2. Frame)
                if reference_frame is not None:
                    normalized = self.histogram_matching(
                        normalized, reference_frame)
                else:
                    reference_frame = normalized.copy()

                # WORKFLOW 3: Temporal Konsistenz
                final_frame = self.temporal_consistency_filter(normalized)

                processed_frames.append(final_frame)

            # WORKFLOW 10: Frame-Interpolation
            processed_frames = self.frame_interpolation_smooth(
                processed_frames)

            # Als MP4 speichern
            output_name = gif_path.stem + "_ultra_consistent.mp4"
            output_path = self.output_dir / output_name

            self.save_as_mp4(processed_frames, output_path, fps=12)

            print(f"âœ… ULTRA-CONSISTENT GESPEICHERT: {output_name}")
            print("ğŸ¯ Alle 10 Workflows erfolgreich angewendet!")
            return True

        except Exception as e:
            print(f"âŒ Fehler: {e}")
            return False

    def save_as_mp4(self, frames, output_path, fps=12):
        """Speichert Frames als hochqualitatives MP4"""
        if not frames:
            return

        h, w = frames[0].shape[:2]
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(str(output_path), fourcc, fps, (w, h))

        for frame in frames:
            out.write(frame)

        out.release()

    def process_problematic_gifs(self):
        """Verarbeitet die problematischen GIFs mit allen Verbesserungen"""
        problematic_gifs = [
            "peer_4.gif",
            "pirate.gif",
            "plant_growth_magic.gif",
            "R (3).gif",
            "sprite_animation.gif"
        ]

        print("\nğŸ¯ ULTRA-CONSISTENT WORKFLOW - PROBLEMATISCHE GIFS")
        print("=" * 80)
        print("ğŸ”§ 10 Workflow-Verbesserungen:")
        print("1. âœ… Globale Farbpaletten-Konsistenz")
        print("2. âœ… Anti-Fraktal SchÃ¤rfung mit RauschunterdrÃ¼ckung")
        print("3. âœ… Temporal Konsistenz mit Frame-Puffer")
        print("4. âœ… Intelligente Pixelart-Stilisierung")
        print("5. âœ… Gradient-basierte KantenverstÃ¤rkung")
        print("6. âœ… Multi-Scale Upscaling")
        print("7. âœ… Histogram-Matching fÃ¼r Beleuchtung")
        print("8. âœ… Struktur-erhaltende GlÃ¤ttung")
        print("9. âœ… Lokale Kontrast-Normalisierung")
        print("10. âœ… Frame-Interpolation fÃ¼r FlÃ¼ssigkeit")
        print("=" * 80)

        success = 0
        for gif_name in problematic_gifs:
            gif_path = self.input_dir / gif_name
            if gif_path.exists():
                if self.process_gif_ultra_consistent(gif_path):
                    success += 1
            else:
                print(f"âš ï¸ Nicht gefunden: {gif_name}")

        print(f"\nğŸ“Š ULTRA-CONSISTENT VERARBEITUNG ABGESCHLOSSEN!")
        print(f"âœ… Erfolgreich: {success}/{len(problematic_gifs)}")
        print(f"ğŸ¯ ANTI-FRAKTAL WORKFLOWS AKTIVIERT!")

        return success > 0


def main():
    upscaler = UltraConsistentUpscaler()

    print("ğŸš€ ULTRA-CONSISTENT PIXEL ART UPSCALER")
    print("ğŸ¯ SPEZIAL-MISSION: ANTI-FRAKTAL & KONSISTENZ-OPTIMIERUNG")
    print("=" * 80)

    success = upscaler.process_problematic_gifs()

    if success:
        print("\nğŸ‰ MISSION ERFOLGREICH!")
        print("ğŸ”¥ LETS FUCKING GOOOOOOOOOOOOOOOOO!")
        print("\nğŸ¯ VERBESSERUNGEN IMPLEMENTIERT:")
        print("â€¢ Keine weiÃŸen Fraktale mehr")
        print("â€¢ Konsistente Farbpalette Ã¼ber Animation")
        print("â€¢ Temporal stabile Frames")
        print("â€¢ Intelligente KantenverstÃ¤rkung")
        print("â€¢ Struktur-erhaltende Verarbeitung")
    else:
        print("\nâŒ Mission fehlgeschlagen")
        sys.exit(1)


if __name__ == "__main__":
    main()
