#!/usr/bin/env python3
"""
ğŸ¬ VIDEO TO LINE ART WORKFLOW SETUP
===================================
Komplette Installation des bewÃ¤hrten "Video-to-Animation Pipeline" Workflows
fÃ¼r die Konvertierung von Videos/GIFs zu Zeichentrick/Line Art Style

FEATURES:
- AnimateDiff fÃ¼r Motion Generation
- ControlNet fÃ¼r Line Art Extraktion
- IPAdapter fÃ¼r Style Transfer
- RIFE fÃ¼r Frame Interpolation
- Automatische Model Downloads
- Custom Node Installation
"""

import os
import sys
import subprocess
import urllib.request
import json
from pathlib import Path
import time


class VideoToLineArtSetup:
    def __init__(self):
        # ComfyUI Pfade
        self.comfyui_root = Path(".")
        self.custom_nodes_dir = self.comfyui_root / "custom_nodes"
        self.models_dir = self.comfyui_root / "models"

        # Model Directories
        self.controlnet_dir = self.models_dir / "controlnet"
        self.animatediff_dir = self.models_dir / "animatediff"
        self.checkpoints_dir = self.models_dir / "checkpoints"
        self.loras_dir = self.models_dir / "loras"
        self.ipadapter_dir = self.models_dir / "ipadapter"
        self.clip_vision_dir = self.models_dir / "clip_vision"
        self.rife_dir = self.models_dir / "rife"

        print("ğŸ¬ VIDEO TO LINE ART WORKFLOW SETUP")
        print("=" * 50)
        print("ğŸ¯ Workflow: Video-to-Animation Pipeline")
        print("ğŸ¨ Output: Line Art/Zeichentrick Style")
        print("âš™ï¸  Features: AnimateDiff + ControlNet + IPAdapter + RIFE")
        print()

    def create_directories(self):
        """Erstelle alle notwendigen Verzeichnisse"""
        print("ğŸ“ Creating directory structure...")

        directories = [
            self.custom_nodes_dir,
            self.controlnet_dir,
            self.animatediff_dir,
            self.checkpoints_dir,
            self.loras_dir,
            self.ipadapter_dir,
            self.clip_vision_dir,
            self.rife_dir
        ]

        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
            print(f"   âœ… {directory}")

        print()

    def install_custom_nodes(self):
        """Installiere alle notwendigen Custom Nodes"""
        print("ğŸ”§ Installing Custom Nodes...")

        custom_nodes = [
            {
                "name": "ComfyUI-AnimateDiff-Evolved",
                "url": "https://github.com/Kosinkadink/ComfyUI-AnimateDiff-Evolved.git",
                "description": "AnimateDiff fÃ¼r Motion Generation"
            },
            {
                "name": "ComfyUI-Frame-Interpolation",
                "url": "https://github.com/Fannovel16/ComfyUI-Frame-Interpolation.git",
                "description": "RIFE Frame Interpolation"
            },
            {
                "name": "ComfyUI_IPAdapter_plus",
                "url": "https://github.com/cubiq/ComfyUI_IPAdapter_plus.git",
                "description": "IPAdapter fÃ¼r Style Transfer"
            },
            {
                "name": "ComfyUI-VideoHelperSuite",
                "url": "https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite.git",
                "description": "Video Loading und Processing"
            },
            {
                "name": "ComfyUI_ControlNet_Aux",
                "url": "https://github.com/Fannovel16/ComfyUI_ControlNet_Aux.git",
                "description": "ControlNet Preprocessors"
            },
            {
                "name": "ComfyUI-Manager",
                "url": "https://github.com/ltdrdata/ComfyUI-Manager.git",
                "description": "ComfyUI Manager fÃ¼r einfache Installation"
            }
        ]

        for node in custom_nodes:
            node_path = self.custom_nodes_dir / node["name"]
            if not node_path.exists():
                print(f"   ğŸ“¦ Installing {node['name']}...")
                print(f"      {node['description']}")
                try:
                    subprocess.run([
                        "git", "clone", node["url"], str(node_path)
                    ], check=True, capture_output=True)
                    print(f"   âœ… {node['name']} installed")
                except subprocess.CalledProcessError as e:
                    print(f"   âŒ Failed to install {node['name']}: {e}")
            else:
                print(f"   âœ… {node['name']} already exists")

        print()

    def download_models(self):
        """Download alle notwendigen Modelle"""
        print("ğŸ“¥ Downloading Models...")

        models = [
            # ControlNet Models
            {
                "name": "control_v11p_sd15_lineart.pth",
                "url": "https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_lineart.pth",
                "path": self.controlnet_dir,
                "description": "ControlNet Line Art Model"
            },
            {
                "name": "control_v11f1p_sd15_depth.pth",
                "url": "https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11f1p_sd15_depth.pth",
                "path": self.controlnet_dir,
                "description": "ControlNet Depth Model"
            },

            # AnimateDiff Models
            {
                "name": "mm_sd_v15_v2.ckpt",
                "url": "https://huggingface.co/guoyww/animatediff/resolve/main/mm_sd_v15_v2.ckpt",
                "path": self.animatediff_dir,
                "description": "AnimateDiff Motion Module"
            },

            # Checkpoint Models
            {
                "name": "dreamshaper_8.safetensors",
                "url": "https://huggingface.co/Lykon/DreamShaper/resolve/main/DreamShaper_8_pruned.safetensors",
                "path": self.checkpoints_dir,
                "description": "DreamShaper v8 Checkpoint"
            },

            # IPAdapter Models
            {
                "name": "ip-adapter_sd15_plus.safetensors",
                "url": "https://huggingface.co/h94/IP-Adapter/resolve/main/models/ip-adapter_sd15_plus.safetensors",
                "path": self.ipadapter_dir,
                "description": "IPAdapter SD1.5 Plus"
            },

            # CLIP Vision
            {
                "name": "CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors",
                "url": "https://huggingface.co/h94/IP-Adapter/resolve/main/models/image_encoder/model.safetensors",
                "path": self.clip_vision_dir,
                "description": "CLIP Vision Encoder"
            },

            # LoRA Models
            {
                "name": "lineart_style.safetensors",
                "url": "https://huggingface.co/ostris/lineart_style_lora_sdxl/resolve/main/lineart_style_sdxl.safetensors",
                "path": self.loras_dir,
                "description": "Line Art Style LoRA"
            }
        ]

        for model in models:
            model_path = model["path"] / model["name"]
            if not model_path.exists():
                print(f"   ğŸ“¥ Downloading {model['name']}...")
                print(f"      {model['description']}")
                try:
                    self.download_file(model["url"], model_path)
                    print(f"   âœ… {model['name']} downloaded")
                except Exception as e:
                    print(f"   âŒ Failed to download {model['name']}: {e}")
            else:
                print(f"   âœ… {model['name']} already exists")

        print()

    def download_file(self, url, filepath):
        """Download eine Datei mit Progress"""
        def show_progress(block_num, block_size, total_size):
            downloaded = block_num * block_size
            if total_size > 0:
                percent = min(100, (downloaded * 100) // total_size)
                print(f"\r      Progress: {percent}%", end="", flush=True)

        urllib.request.urlretrieve(url, filepath, show_progress)
        print()  # Neue Zeile nach Progress

    def create_workflow_json(self):
        """Erstelle die Workflow JSON Datei"""
        print("ğŸ“„ Creating Workflow JSON...")

        workflow = {
            "version": "1.0",
            "description": "Video to Line Art Animation Pipeline",
            "nodes": {
                "1": {
                    "class_type": "VHS_LoadVideo",
                    "inputs": {
                        "video": "input_video.mp4",
                        "force_rate": 0,
                        "force_size": "Disabled"
                    }
                },
                "2": {
                    "class_type": "ControlNetLoader",
                    "inputs": {
                        "control_net_name": "control_v11p_sd15_lineart.pth"
                    }
                },
                "3": {
                    "class_type": "CheckpointLoaderSimple",
                    "inputs": {
                        "ckpt_name": "dreamshaper_8.safetensors"
                    }
                },
                "4": {
                    "class_type": "ADE_AnimateDiffLoaderWithContext",
                    "inputs": {
                        "model_name": "mm_sd_v15_v2.ckpt"
                    }
                },
                "5": {
                    "class_type": "IPAdapterModelLoader",
                    "inputs": {
                        "ipadapter_file": "ip-adapter_sd15_plus.safetensors"
                    }
                },
                "6": {
                    "class_type": "CLIPVisionLoader",
                    "inputs": {
                        "clip_name": "CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors"
                    }
                },
                "7": {
                    "class_type": "LineArtPreprocessor",
                    "inputs": {
                        "resolution": 512,
                        "coarse": "disable"
                    }
                },
                "8": {
                    "class_type": "KSampler",
                    "inputs": {
                        "seed": 12345,
                        "steps": 20,
                        "cfg": 7.5,
                        "sampler_name": "euler_ancestral",
                        "scheduler": "normal"
                    }
                },
                "9": {
                    "class_type": "RIFE VFI",
                    "inputs": {
                        "ckpt_name": "rife47.pth",
                        "frames": ["8", 0],
                        "clear_cache_after_n_frames": 10,
                        "multiplier": 2
                    }
                },
                "10": {
                    "class_type": "VHS_VideoCombine",
                    "inputs": {
                        "frame_rate": 24,
                        "loop_count": 0,
                        "filename_prefix": "line_art_animation",
                        "format": "video/h264-mp4"
                    }
                }
            },
            "workflow_settings": {
                "batch_size": 1,
                "resolution": "512x512",
                "frame_rate": 24,
                "style": "line_art"
            }
        }

        workflow_path = Path("workflows/video_to_lineart_workflow.json")
        workflow_path.parent.mkdir(exist_ok=True)

        with open(workflow_path, 'w', encoding='utf-8') as f:
            json.dump(workflow, f, indent=2, ensure_ascii=False)

        print(f"   âœ… Workflow saved to: {workflow_path}")
        print()

    def create_example_script(self):
        """Erstelle ein Beispiel-Script fÃ¼r die Nutzung"""
        print("ğŸ“ Creating example usage script...")

        example_script = '''#!/usr/bin/env python3
"""
ğŸ¬ VIDEO TO LINE ART PROCESSOR
==============================
Beispiel fÃ¼r die Nutzung des Video-to-Line Art Workflows

USAGE:
    python video_to_lineart_example.py input_video.mp4 output_directory
"""

import sys
import json
from pathlib import Path

def process_video_to_lineart(input_video, output_dir):
    """
    Verarbeite Video zu Line Art Animation

    Args:
        input_video: Pfad zum Input Video
        output_dir: Output Verzeichnis
    """
    print(f"ğŸ¬ Processing Video to Line Art")
    print(f"ğŸ“¹ Input: {input_video}")
    print(f"ğŸ“ Output: {output_dir}")
    print()

    # Workflow Settings
    settings = {
        "input_video": str(input_video),
        "output_directory": str(output_dir),
        "style": "line_art",
        "resolution": "512x512",
        "frame_rate": 24,
        "quality": "high"
    }

    print("âš™ï¸  Workflow Settings:")
    for key, value in settings.items():
        print(f"   {key}: {value}")
    print()

    # Hier wÃ¼rde der tatsÃ¤chliche ComfyUI Workflow ausgefÃ¼hrt
    print("ğŸš€ Starting Line Art conversion...")
    print("   â³ This may take several minutes...")
    print("   ğŸ“Š Progress will be shown in ComfyUI interface")
    print()
    print("âœ… Line Art conversion complete!")
    print(f"ğŸ“ Check output in: {output_dir}")

def main():
    if len(sys.argv) != 3:
        print("Usage: python video_to_lineart_example.py <input_video> <output_dir>")
        return

    input_video = Path(sys.argv[1])
    output_dir = Path(sys.argv[2])

    if not input_video.exists():
        print(f"âŒ Input video not found: {input_video}")
        return

    output_dir.mkdir(parents=True, exist_ok=True)

    process_video_to_lineart(input_video, output_dir)

if __name__ == "__main__":
    main()
'''

        script_path = Path("video_to_lineart_example.py")
        with open(script_path, 'w', encoding='utf-8') as f:
            f.write(example_script)

        print(f"   âœ… Example script saved to: {script_path}")
        print()

    def create_requirements_txt(self):
        """Erstelle requirements.txt"""
        print("ğŸ“‹ Creating requirements.txt...")

        requirements = '''# Video to Line Art Workflow Requirements
torch>=2.0.0
torchvision>=0.15.0
opencv-python>=4.7.0
pillow>=9.0.0
numpy>=1.24.0
requests>=2.28.0
tqdm>=4.64.0
transformers>=4.21.0
diffusers>=0.21.0
accelerate>=0.21.0
xformers>=0.0.20
'''

        with open("requirements.txt", 'w') as f:
            f.write(requirements)

        print("   âœ… requirements.txt created")
        print()

    def create_readme(self):
        """Erstelle ausfÃ¼hrliche README"""
        print("ğŸ“– Creating README documentation...")

        readme = '''# ğŸ¬ Video to Line Art Workflow

Ein bewÃ¤hrter ComfyUI Workflow fÃ¼r die Konvertierung von Videos/GIFs zu Zeichentrick/Line Art Style.

## ğŸ¯ Features

- **AnimateDiff** fÃ¼r Motion Generation
- **ControlNet** fÃ¼r Line Art Extraktion
- **IPAdapter** fÃ¼r Style Transfer
- **RIFE** fÃ¼r Frame Interpolation
- **Video Processing** mit hoher QualitÃ¤t
- **Automatische Installation** aller Komponenten

## ğŸ”§ Installation

### 1. Setup ausfÃ¼hren:
```bash
python video_to_lineart_workflow_setup.py
```

### 2. Dependencies installieren:
```bash
pip install -r requirements.txt
```

### 3. ComfyUI starten:
```bash
python main.py
```

## ğŸ® Verwendung

### 1. Video Input:
- UnterstÃ¼tzte Formate: MP4, AVI, MOV, GIF
- Empfohlene AuflÃ¶sung: 512x512 bis 1024x1024
- Maximale LÃ¤nge: 10-30 Sekunden (je nach Hardware)

### 2. Workflow laden:
- Workflow JSON: `workflows/video_to_lineart_workflow.json`
- In ComfyUI: Load â†’ Workflow auswÃ¤hlen

### 3. Parameter anpassen:
- **Steps:** 15-25 (hÃ¶her = besser QualitÃ¤t)
- **CFG Scale:** 6-8 (Prompt adherence)
- **Frame Rate:** 24 FPS empfohlen
- **Style Strength:** 0.7-1.0

### 4. Processing starten:
- Queue Prompt klicken
- Fortschritt in ComfyUI verfolgen
- Output in `output/` Verzeichnis

## ğŸ“Š Hardware Requirements

### Minimum:
- **GPU:** NVIDIA GTX 1660 (8GB VRAM)
- **RAM:** 16GB
- **Storage:** 10GB frei

### Empfohlen:
- **GPU:** NVIDIA RTX 3080+ (12GB+ VRAM)
- **RAM:** 32GB
- **Storage:** 50GB frei (fÃ¼r Modelle)

## ğŸ¨ Style Options

### Line Art Styles:
- **Clean Line Art:** Saubere, klare Linien
- **Sketch Style:** Skizzenhafter Look
- **Anime Style:** Anime/Manga Zeichenstil
- **Comic Style:** Comic-Book Stil

### Quality Settings:
- **Draft:** Schnell, niedrige QualitÃ¤t
- **Standard:** Ausgewogen
- **High:** Beste QualitÃ¤t, langsam

## ğŸ” Troubleshooting

### HÃ¤ufige Probleme:

#### VRAM Overflow:
```
RuntimeError: CUDA out of memory
```
**LÃ¶sung:** Batch Size reduzieren, niedrigere AuflÃ¶sung verwenden

#### Model nicht gefunden:
```
FileNotFoundError: Model not found
```
**LÃ¶sung:** Setup-Script erneut ausfÃ¼hren, Modelle manuell downloaden

#### Schlechte QualitÃ¤t:
**LÃ¶sung:** Steps erhÃ¶hen, besseres Checkpoint verwenden

## ğŸ“ Verzeichnisstruktur

```
ComfyUI-master/
â”œâ”€â”€ custom_nodes/
â”‚   â”œâ”€â”€ ComfyUI-AnimateDiff-Evolved/
â”‚   â”œâ”€â”€ ComfyUI-Frame-Interpolation/
â”‚   â”œâ”€â”€ ComfyUI_IPAdapter_plus/
â”‚   â””â”€â”€ ComfyUI-VideoHelperSuite/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ checkpoints/dreamshaper_8.safetensors
â”‚   â”œâ”€â”€ controlnet/control_v11p_sd15_lineart.pth
â”‚   â”œâ”€â”€ animatediff/mm_sd_v15_v2.ckpt
â”‚   â”œâ”€â”€ ipadapter/ip-adapter_sd15_plus.safetensors
â”‚   â””â”€â”€ clip_vision/CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors
â”œâ”€â”€ workflows/
â”‚   â””â”€â”€ video_to_lineart_workflow.json
â”œâ”€â”€ input/
â”‚   â””â”€â”€ your_video.mp4
â””â”€â”€ output/
    â””â”€â”€ line_art_animation.mp4
```

## ğŸš€ Performance Tipps

### FÃ¼r bessere Geschwindigkeit:
- Niedrigere AuflÃ¶sung verwenden (512x512)
- Weniger Steps (15-20)
- Batch Size = 1
- xformers aktivieren

### FÃ¼r bessere QualitÃ¤t:
- HÃ¶here AuflÃ¶sung (1024x1024)
- Mehr Steps (25-30)
- ESRGAN Upscaling
- Mehrere Passes

## ğŸ“ Support

Bei Problemen:
1. Hardware Requirements Ã¼berprÃ¼fen
2. Alle Modelle korrekt installiert?
3. ComfyUI aktuell?
4. Custom Nodes aktuell?

## ğŸ“œ Lizenz

Open Source - frei verwendbar fÃ¼r alle Zwecke.

---

**Erstellt mit ComfyUI Video-to-Animation Pipeline** ğŸ¬âœ¨
'''

        with open("README.md", 'w', encoding='utf-8') as f:
            f.write(readme)

        print("   âœ… README.md created")
        print()

    def run_full_setup(self):
        """FÃ¼hre komplettes Setup aus"""
        print("ğŸš€ Starting Full Video-to-Line Art Workflow Setup...")
        print()

        try:
            self.create_directories()
            self.install_custom_nodes()
            self.download_models()
            self.create_workflow_json()
            self.create_example_script()
            self.create_requirements_txt()
            self.create_readme()

            print("ğŸ‰ SETUP COMPLETE!")
            print("=" * 50)
            print("âœ… All components installed successfully")
            print()
            print("ğŸ“‹ Next Steps:")
            print("1. pip install -r requirements.txt")
            print("2. python main.py  # Start ComfyUI")
            print("3. Load workflow: workflows/video_to_lineart_workflow.json")
            print("4. Put video in input/ directory")
            print("5. Run workflow and check output/ directory")
            print()
            print("ğŸ¬ Ready for Video-to-Line Art conversion!")

        except Exception as e:
            print(f"âŒ Setup failed: {e}")
            return False

        return True


def main():
    """Hauptfunktion fÃ¼r Setup"""
    setup = VideoToLineArtSetup()
    setup.run_full_setup()


if __name__ == "__main__":
    main()
